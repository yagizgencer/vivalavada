{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6840575b4ff911db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Project Milestone P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains the first data manipulations and analysis. \n",
    "The used datasets comme from two websites: BeerAdvocate and RateBeer. We also have the data present in the two datasets. \n",
    "For each website, the used files are:   \n",
    "- beers.csv \n",
    "- breweries.csv\n",
    "- users.csv\n",
    "- ratings.txt\n",
    "- reviews.txt\n",
    "\n",
    "In order to be able to use the ratings, the text file was converted into csv using the script txt-to-csv.py. \n",
    "\n",
    "We firstly combine the data from the two datasets, while taking into consideration the data present in both datasets. "
   ],
   "id": "ccf502ce8ec15014"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Merging (instead of matching) the data from the two websites into one."
   ],
   "id": "92f71aab2de68693"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:48:34.920449100Z",
     "start_time": "2023-12-12T09:48:33.340622900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display\n",
    "from geopy.distance import geodesic\n",
    "import math\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the datasets"
   ],
   "id": "6868a9e8e9b25543"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f434393123b0c09c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:48:38.089756300Z",
     "start_time": "2023-12-12T09:48:34.920449100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beers_rb = pd.read_csv(\"dataset/RateBeer/beers.csv\")\n",
    "beers_ba = pd.read_csv(\"dataset/BeerAdvocate/beers.csv\")\n",
    "beers_matched = pd.read_csv(\"dataset/MatchedData/beers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22286c46677d8f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:48:38.105381700Z",
     "start_time": "2023-12-12T09:48:38.089756300Z"
    }
   },
   "outputs": [],
   "source": [
    "users_rb = pd.read_csv(\"dataset/RateBeer/users.csv\")\n",
    "users_ba = pd.read_csv(\"dataset/BeerAdvocate/users.csv\")\n",
    "users_matched = pd.read_csv(\"dataset/MatchedData/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef51f08d503665",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.105381700Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_rb = pd.read_csv(\"dataset/RateBeer/ratings-reviews.csv\")\n",
    "ratings_ba = pd.read_csv(\"dataset/BeerAdvocate/ratings.csv\")\n",
    "ratings_matched = pd.read_csv(\"dataset/MatchedData/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e836f966ded56f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.105381700Z"
    }
   },
   "outputs": [],
   "source": [
    "brewery_rb = pd.read_csv(\"dataset/RateBeer/breweries.csv\")\n",
    "brewery_ba = pd.read_csv(\"dataset/BeerAdvocate/breweries.csv\")\n",
    "brewery_matched = pd.read_csv(\"dataset/MatchedData/breweries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Changing the beer_id in the BeerAdvocate dataset, so that each beer id is unique"
   ],
   "id": "b7b1bfd6c7d14af6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2ce4373c6ff8c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.105381700Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID's of the beers coming from the two websites should be unique. However, there are intersections for now, which would cause problems after merging. That's why we add 1000000 to id's of the BeerAdvocate beers.\n",
    "\n",
    "ba_id = beers_ba['beer_id'].values\n",
    "rb_id = beers_rb['beer_id'].values\n",
    "ba_id = ba_id + 1000000\n",
    "\n",
    "#Checking whether the overlapping problem is solved:\n",
    "if np.intersect1d(ba_id, rb_id).size > 0:\n",
    "    print(np.intersect1d(ba_id, rb_id).size)\n",
    "    \n",
    "beers_ba['beer_id'] = beers_ba['beer_id'] + 1000000\n",
    "ratings_ba['beer_id'] = ratings_ba['beer_id'] + 1000000\n",
    "beers_matched['ba.5'][1:] = beers_matched['ba.5'][1:].astype(int) + 1000000\n",
    "beers_matched['rb.4'][1:] = beers_matched['rb.4'][1:].astype(int)\n",
    "\n",
    "#Finding the dictionary that maps the beers from BeerAdvocate to RateBeer (for the beers that are the same) by the help of matched data provided:\n",
    "ba_to_rb_beer_id_dict = dict(zip(beers_matched['ba.5'], beers_matched['rb.4']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Changing the brewery_id in the BeerAdvocate dataset, so that each brewery id is unique"
   ],
   "id": "554b58df5266449f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e50b5920fab4b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.105381700Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID's of the breweries coming from the two websites should be unique. However, there are intersections for now, which would cause problems after merging. That's why we add 1000000 to id's of the BeerAdvocate breweries, again.\n",
    "\n",
    "ba_id = brewery_ba['id'].values\n",
    "rb_id = brewery_rb['id'].values\n",
    "ba_id = ba_id + 1000000\n",
    "\n",
    "#Checking whether the overlapping problem is solved:\n",
    "if np.intersect1d(ba_id, rb_id).size > 0:\n",
    "    print(np.intersect1d(ba_id, rb_id).size)\n",
    "\n",
    "brewery_ba['id'] = brewery_ba['id'] + 1000000\n",
    "beers_ba['brewery_id'] = beers_ba['brewery_id'] + 1000000\n",
    "ratings_ba['brewery_id'] = ratings_ba['brewery_id'] + 1000000\n",
    "brewery_matched['ba'][1:] = brewery_matched['ba'][1:].astype(int) + 1000000\n",
    "brewery_matched['rb'][1:] = brewery_matched['rb'][1:].astype(int)\n",
    "\n",
    "#Finding the dictionary that maps the breweries from BeerAdvocate to RateBeer (for the breweries that are the same) by the help of matched data provided:\n",
    "ba_to_rb_brewery_id_dict = dict(zip(brewery_matched['ba'], brewery_matched['rb']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking for the users id"
   ],
   "id": "fa24182eec69334c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92dbeba7b321f37",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:48:38.136622900Z",
     "start_time": "2023-12-12T09:48:38.105381700Z"
    }
   },
   "outputs": [],
   "source": [
    "ba_id = users_ba['user_id'].values\n",
    "rb_id = users_rb['user_id'].astype(str).values\n",
    "\n",
    "#Checking if there is the same ID overlap problem for the users as well:\n",
    "if np.intersect1d(ba_id, rb_id).size > 0:\n",
    "    print(np.intersect1d(ba_id, rb_id).size)\n",
    "\n",
    "#Finding the dictionary that maps the users from BeerAdvocate to RateBeer (for the users that are the same) by the help of matched data provided:  \n",
    "ba_to_rb_user_id_dict = dict(zip(users_matched['ba.4'], users_matched['rb.3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finding the style names present in each dataset, and harmonize the styles between the websites"
   ],
   "id": "b434ed34433a7ad4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ad78132e53f68",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.121003800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finding the style of beers present in the matched data and RateBeer data separately:\n",
    "matched_rb_beers = beers_matched['rb.12'].unique()\n",
    "all_rb_beers = beers_rb['style'].unique()\n",
    "\n",
    "#Finding the styles that are in RateBeer but not in the matched data:\n",
    "elements_not_in_matched = [element for element in all_rb_beers if element not in matched_rb_beers]\n",
    "\n",
    "#The styles that are in RateBeer but not in the matched data have received very few ratings. Furthermore, we will map the styles of BeerAdvocate to the styles of RateBeer using the matched data. Since no BeerAdvocate beers will be mapped to this set of beers, they will appear even less popular in the results. Therefore, we eliminate these styles here.\n",
    "beers_rb = beers_rb[~beers_rb['style'].isin(elements_not_in_matched)]\n",
    "ratings_rb = ratings_rb[~ratings_rb['style'].isin(elements_not_in_matched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ff370e25970b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.121003800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Inspecting the matched data we realize that there is no one to one matched between the \"style\" labels of the two websites. For example: a beer with style label of \"English Pale Ale\" on BeerAdvocate is labeled as having the style \"Golden Ale/Blond Ale\" in RateBeer. But another beer, whose style is also \"English Pale Ale\" on BeerAdvocate has this time style label of \"Amber Ale\" in RateBeer. \n",
    "\n",
    "# In order to match the BeerAdvocate styles to the RateBeer styles, we look at all the instances of each unique beer in BeerAdvocate and find its most frequent corresponding style in RateBeer. We then collect each unique style in BeerAdvocate, its most frequent match and the most frequent match count in a dataframe.\n",
    "\n",
    "ba_to_rb = []\n",
    "for style_value in beers_matched['ba.14'].unique():\n",
    "    # Filter the DataFrame for rows where 'style_column1' matches the current value\n",
    "    filtered_rows = beers_matched[beers_matched['ba.14'] == style_value]\n",
    "    \n",
    "    # Find the most frequent match in 'style_column2'\n",
    "    most_frequent_match = filtered_rows['rb.12'].mode().iloc[0]\n",
    "    \n",
    "    # Count the occurrences of the most frequent match\n",
    "    match_count = filtered_rows[filtered_rows['rb.12'] == most_frequent_match].shape[0]\n",
    "    \n",
    "    # Append the results to the result DataFrame\n",
    "    # \n",
    "    ba_to_rb.append({'style_column1': style_value,\n",
    "                                  'most_frequent_match': most_frequent_match,\n",
    "                                  'match_count': match_count})\n",
    "ba_to_rb.pop(0)\n",
    "ba_to_rb_df = pd.DataFrame(ba_to_rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.121003800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Printing the resulting dataFrame: \n",
    "ba_to_rb_df.head()"
   ],
   "id": "6ff04fdf381a1697"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0603ef900b530e7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.121003800Z"
    }
   },
   "outputs": [],
   "source": [
    "#We see that all the styles of the BeerAdvocate are mapped to 71 different beer styles in RateBeer using the above-explained procedure. We would like to have one-to-one mapping between the styles of two websites such that not only all the styles of BeerAdvocate are mapped to a style of RateBeer, all styles of RateBeer are also mapped to a BeerAdvocate style.\n",
    "\n",
    "#For this, we first find which styles of RateBeer are not mapped to a BeerAdvocate beer in the previous cell.\n",
    "rb_to_ba_styles = ba_to_rb_df.most_frequent_match.unique()\n",
    "matched_rb_styles = beers_matched['rb.12'].unique()\n",
    "elements_not_in_ba = [element for element in matched_rb_styles if element not in rb_to_ba_styles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107882c51c50ca40",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.121003800Z"
    }
   },
   "outputs": [],
   "source": [
    "#For the RateBeer styles that are not mapped, we first find their most frequent match in BeerAdvocate, and then map it back to one of the RateBeer styles as done before. By doing this, we make sure that all the BeerAdvocate styles are mapped to a RateBeer style and vice versa.\n",
    "\n",
    "rb_to_ba_df = []\n",
    "for style_value in elements_not_in_ba:\n",
    "    # Filter the DataFrame for rows where 'style_column1' matches the current value\n",
    "    filtered_rows = beers_matched[beers_matched['rb.12'] == style_value]\n",
    "    \n",
    "    # Find the most frequent match in 'style_column2'\n",
    "    most_frequent_match = filtered_rows['ba.14'].mode().iloc[0]\n",
    "    \n",
    "    # Count the occurrences of the most frequent match\n",
    "    match_count = filtered_rows[filtered_rows['ba.14'] == most_frequent_match].shape[0]\n",
    "    \n",
    "    # Append the results to the result DataFrame\n",
    "    rb_to_ba_df.append({'style_column1': style_value,\n",
    "                                  'most_frequent_match': most_frequent_match,\n",
    "                                  'match_count': match_count})\n",
    "rb_to_ba_df = pd.DataFrame(rb_to_ba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a4dd6278015e7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.136622900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finding the dictionary that maps the \"unmapped\" RateBeer styles to one of the BeerAdvocate styles:\n",
    "\n",
    "rb_to_ba_dict = dict(zip(rb_to_ba_df['style_column1'], rb_to_ba_df['most_frequent_match']))\n",
    "beers_matched['rb.12'] = beers_matched['rb.12'].replace(rb_to_ba_dict)\n",
    "beers_rb['style'] = beers_rb['style'].replace(rb_to_ba_dict)\n",
    "ratings_rb['style'] = ratings_rb['style'].replace(rb_to_ba_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.136622900Z"
    }
   },
   "outputs": [],
   "source": [
    "display(rb_to_ba_dict)"
   ],
   "id": "99eeb2b0801b747a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db5533dbfd3813",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.136622900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Mapping these styles back to one of the 71 RateBeer styles:\n",
    "\n",
    "ba_to_rb_dict = dict(zip(ba_to_rb_df['style_column1'], ba_to_rb_df['most_frequent_match']))\n",
    "beers_ba['style'] = beers_ba['style'].replace(ba_to_rb_dict)\n",
    "beers_matched['rb.12'] = beers_matched['rb.12'].replace(ba_to_rb_dict)\n",
    "beers_rb['style'] = beers_rb['style'].replace(ba_to_rb_dict)\n",
    "ratings_rb['style'] = ratings_rb['style'].replace(ba_to_rb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a516e6c6976da5df",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.136622900Z"
    }
   },
   "outputs": [],
   "source": [
    "matched_rb_ids = beers_matched['rb.4'][1:]\n",
    "matched_ba_ids = beers_matched['ba.5'][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. After those modifications, merging of the datasets"
   ],
   "id": "ead6ae4fcc9f63cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946efe9e6ed43b2f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.136622900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing the matched beers from the two websites before merging:\n",
    "\n",
    "rb_without_matched = beers_rb[~beers_rb['beer_id'].isin(matched_rb_ids)]\n",
    "ba_without_matched = beers_ba[~beers_ba['beer_id'].isin(matched_ba_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a1992d2ddba7b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:48:38.298119600Z",
     "start_time": "2023-12-12T09:48:38.152272200Z"
    }
   },
   "outputs": [],
   "source": [
    "#First, we take only the necessary columns of beer datasets and rename them conveniently. \n",
    "\n",
    "columns_to_take = ['beer_id', 'beer_name', 'brewery_id', 'brewery_name', 'style', 'abv']\n",
    "column_name_mapping = {'rb.4': 'beer_id', 'rb.5': 'beer_name', 'rb.7': 'brewery_id', 'rb.8': 'brewery_name', 'rb.12': 'style', 'rb': 'abv'}\n",
    "beers_matched.rename(columns = column_name_mapping, inplace = True)\n",
    "\n",
    "#We first merge the beer datasets from the two websites. Note that the matched beers were eliminated from these datasets beforehand.\n",
    "merged_beers = pd.concat([rb_without_matched[columns_to_take], ba_without_matched[columns_to_take]], axis=0, ignore_index = True)\n",
    "\n",
    "#Now we include the matched beers in the merged datasets, making sure that the matched beers are not repeated but included only once.\n",
    "merged_beers = pd.concat([merged_beers, beers_matched.iloc[1:][columns_to_take]], axis=0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ae795ab13f6cc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.154974900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Before merging the breweries, removing the matched breweries from BeerAdvocate and then merging this directly with the original brewery data of RateBeer:\n",
    "\n",
    "matched_ba_ids = brewery_matched['ba'][1:]\n",
    "ba_without_matched = brewery_ba[~brewery_ba['id'].isin(matched_ba_ids)]\n",
    "merged_breweries = pd.concat([brewery_rb, ba_without_matched], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea49d18ba1e4d8e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.154974900Z"
    }
   },
   "outputs": [],
   "source": [
    "#Before merging the users, removing the matched users from BeerAdvocate and then merging this directly with the original user data of RateBeer:\n",
    "\n",
    "matched_ba_ids = users_matched['ba.4'][1:]\n",
    "ba_without_matched = users_ba[~users_ba['user_id'].isin(matched_ba_ids)]\n",
    "merged_users = pd.concat([users_rb, ba_without_matched], axis = 0, ignore_index = True)\n",
    "merged_users['user_id'] = merged_users['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794733fceb481f6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.154974900Z"
    }
   },
   "outputs": [],
   "source": [
    "#The BeerAdvocate dataset user_id's, beer_id's and brewery_id's are changed to be aligned to the Ratebeer dataset, according to the association described earlier.  Before merging the ratings data of the two websites, we update the corresponding columns of the BeerAdvocate datasets using the dictionaries calculated beforehand. \n",
    "\n",
    "ratings_ba['style'] = ratings_ba['style'].replace(ba_to_rb_dict)\n",
    "ratings_ba['user_id'] = ratings_ba['user_id'].replace(ba_to_rb_user_id_dict)\n",
    "ratings_ba['beer_id'] = ratings_ba['beer_id'].replace(ba_to_rb_beer_id_dict)\n",
    "ratings_ba['brewery_id'] = ratings_ba['brewery_id'].replace(ba_to_rb_brewery_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9024eb80654814",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.170597Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adjusting the data types:\n",
    "\n",
    "ratings_matched = ratings_matched.iloc[1:]\n",
    "\n",
    "ratings_matched['ba.15'] = ratings_matched['ba.15'].astype(str)\n",
    "ratings_matched['ba.7'] = ratings_matched['ba.7'].astype(np.int64)\n",
    "ratings_matched['ba.3'] = ratings_matched['ba.3'].astype(np.int64)\n",
    "\n",
    "ratings_matched['rb.14'] = ratings_matched['rb.14'].astype(str)\n",
    "ratings_matched['rb.7'] = ratings_matched['rb.7'].astype(np.int64)\n",
    "ratings_matched['rb.3'] = ratings_matched['rb.3'].astype(np.int64)\n",
    "\n",
    "# List of usernames present in both websites, using BA information:\n",
    "listed_ba_user = list(ratings_matched['ba.15'])\n",
    "listed_ba_date = list(ratings_matched['ba.7'])\n",
    "listed_ba_beer = list(ratings_matched['ba.3'])\n",
    "\n",
    "# List of usernames present in both websites, using RB information:\n",
    "listed_rb_user=list(ratings_matched['rb.14'])\n",
    "listed_rb_date = list(ratings_matched['rb.7'])\n",
    "listed_rb_beer = list(ratings_matched['rb.3'])\n",
    "\n",
    "# Creating triples to be able to uniquely identify the matched ratings (ratings that are given for the same beer in the two websites by the same user) in each of the websites:\n",
    "couple_ba = list(zip(listed_rb_user, listed_ba_date, listed_rb_beer))\n",
    "couple_rb = list(zip(listed_rb_user, listed_rb_date, listed_rb_beer))\n",
    "\n",
    "# Selecting only the rows that do not match the triples for BeerAdvocate, dropping review column and adding a new column to indicate the website for the future z-score calculations:\n",
    "ratings_ba['user_id'] = ratings_ba['user_id'].astype(str)\n",
    "ratings_ba['date'] = ratings_ba['date'].astype(np.int64)\n",
    "ratings_ba['beer_id'] = ratings_ba['beer_id'].astype(np.int64)\n",
    "df_ba_removed = ratings_ba[~ratings_ba.set_index(['user_id', 'date', 'beer_id']).index.isin(couple_ba)]\n",
    "df_ba_removed = df_ba_removed.drop('review', axis = 1)\n",
    "df_ba_removed['website'] = 1\n",
    "\n",
    "# Selecting only the rows that do not match the triples for RateBeer and adding a new column to \n",
    "# indicate the website for the future z-score calculations:\n",
    "ratings_rb['user_id'] = ratings_rb['user_id'].astype(str)\n",
    "ratings_rb['date'] = ratings_rb['date'].astype(np.int64)\n",
    "ratings_rb['beer_id'] = ratings_rb['beer_id'].astype(np.int64)\n",
    "df_rb_removed = ratings_rb[~ratings_rb.set_index(['user_id', 'date', 'beer_id']).index.isin(couple_rb)]\n",
    "df_rb_removed['website'] = 0\n",
    "\n",
    "merged_ratings = pd.concat([df_ba_removed, df_rb_removed], axis = 0, ignore_index=True)\n",
    "\n",
    "merged_ratings['date'] = merged_ratings['date'].apply(convert_unix_timestamp)\n",
    "merged_ratings['year'] = merged_ratings['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d27bb878ebdb4b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.170597Z"
    }
   },
   "outputs": [],
   "source": [
    "#Recalculating the number of ratings:\n",
    "\n",
    "rating_counts_by_user = merged_ratings.groupby('user_id')['beer_id'].count()\n",
    "rating_counts_by_user_dict = rating_counts_by_user.to_dict()\n",
    "merged_users['nbr_ratings'] = merged_users['nbr_ratings'].replace(rating_counts_by_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d8e581e07e867",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.170597Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_beers.to_csv(\"dataset/MergedData/beers.csv\", index = False)\n",
    "merged_breweries.to_csv(\"dataset/MergedData/breweries.csv\", index = False)\n",
    "merged_users.to_csv(\"dataset/MergedData/users.csv\", index = False)\n",
    "merged_ratings.to_csv(\"dataset/MergedData/ratings.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14db6909a698bf2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.170597Z"
    }
   },
   "outputs": [],
   "source": [
    "beers = pd.read_csv('dataset/MergedData/beers.csv')\n",
    "breweries = pd.read_csv('dataset/MergedData/breweries.csv')\n",
    "ratings = pd.read_csv('dataset/MergedData/ratings.csv', dtype = {'user_id': str})\n",
    "users = pd.read_csv('dataset/MergedData/users.csv', dtype = {'user_id': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a261f951aa7449",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### PART 2: Preprocessing of the merged data before initial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing of the ratings\n",
    "\n",
    "We compute the z-score for each rating and sub-rating feature\n",
    "\n",
    "Two main observations were made here: \n",
    " - The mean rating is not the same for the two websites\n",
    " - The mean rating augments with the years\n",
    "\n",
    "Moreover, we found out that the range of data was not the same between the aspects: for example, for RateBeer, the \"overall\" rating goes from 1 to 20, and on BeerAdvocate, from 1 to 5. Within one website, the range of different metrics changed too. Normalizing was then very important, especially for the next steps, where correlation between each aspect and the total rating will be studied. Indeed, the range of data could influence the computation of the coefficients for the regression for example.\n",
    "\n",
    "As we do not want those effects to be reflected on our results, the z-score was calculated. \n",
    "For each feature, we substracted the mean for this year and the corresponding website, and divided by the standard deviation."
   ],
   "id": "f42660d7bc9b328a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.186246700Z"
    }
   },
   "outputs": [],
   "source": [
    "f = sns.barplot(data=ratings, x='year', y='rating', hue='website', order=sorted(ratings['year'].unique()), palette='mako')\n",
    "f.tick_params(axis='x', which='major', length = 10, width=3, direction='inout')\n",
    "plt.xticks(rotation=45)\n",
    "f.set_title(\"Mean rating accross the years\")\n",
    "\n",
    "handles, labels = f.get_legend_handles_labels()\n",
    "f.legend(handles, ['RateBeer', 'BeerAdvocate'], title='Website', loc='upper left')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "eda1b651282dbf56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92408d1f149ec5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.186246700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculating z-scores for all types of ratings by normalizing with respect to the mean and standard deviation of the corresponding website's ratings of that year:\n",
    "\n",
    "ratings['rating'] = (ratings['rating'] - ratings.groupby(['year', 'website'])['rating'].transform('mean')) / ratings.groupby(['year', 'website'])['rating'].transform('std')\n",
    "\n",
    "ratings['appearance'] = (ratings['appearance'] - ratings.groupby(['year', 'website'])['appearance'].transform('mean')) / ratings.groupby(['year', 'website'])['appearance'].transform('std')\n",
    "\n",
    "ratings['aroma'] = (ratings['aroma'] - ratings.groupby(['year', 'website'])['aroma'].transform('mean')) / ratings.groupby(['year', 'website'])['aroma'].transform('std')\n",
    "\n",
    "ratings['palate'] = (ratings['palate'] - ratings.groupby(['year', 'website'])['palate'].transform('mean')) / ratings.groupby(['year', 'website'])['palate'].transform('std')\n",
    "\n",
    "ratings['taste'] = (ratings['taste'] - ratings.groupby(['year', 'website'])['taste'].transform('mean')) / ratings.groupby(['year', 'website'])['taste'].transform('std')\n",
    "\n",
    "ratings['overall'] = (ratings['overall'] - ratings.groupby(['year', 'website'])['overall'].transform('mean')) / ratings.groupby(['year', 'website'])['overall'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25626f2699cc529",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.186246700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualizing the ratings dataframe as a sanity check:\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a46d354467a68",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.186246700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Inspecting some statistics of our dataset:\n",
    "\n",
    "print(f\"Number of unique beers: {len(beers['beer_id'].unique())}\")\n",
    "print(f\"Number of beers with ratings: {len(ratings['beer_id'].unique())}\\n\")\n",
    "\n",
    "print(f\"Number of unique beer styles: {len(beers['style'].unique())}\\n\")\n",
    "\n",
    "print(f\"Number of unique breweries: {len(breweries['id'].unique())}\")\n",
    "print(f\"Number of breweries with ratings: {len(ratings['brewery_id'].unique())}\\n\")\n",
    "\n",
    "print(f\"Number of unique users: {len(users['user_id'].unique())}\")\n",
    "print(f\"Number of users with ratings: {len(ratings['user_id'].unique())}\\n\")\n",
    "\n",
    "print(f\"Total number of ratings: {len(ratings)}\")\n",
    "\n",
    "print(\"Nan: \")\n",
    "ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting to note that there is exactly the same number of missing values for the ratings of the different aspects of the beer. It is probably due to the fact that there are two \"levels\" of rating: an overall grade, that would be quicker to make, or a rating for each aspect (in which case the user has to respond to all the fields). \n",
    "\n",
    "When we will study the effect of each aspect, those NaN for those and for abv will be ignored. However, those values are not relevant for all our research, so we will keep all the values in a first time. \n",
    "\n",
    "The text review and usernames won't be analyzed eather, so the NaN are not problematic."
   ],
   "id": "e1efafa0434da85c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocessing of the alcohol content\n",
    "\n",
    "We check the values of abv, and filter the dataset."
   ],
   "id": "4329f4261c9e312f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0233b7a5c114cb9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.201838800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Looking at the distribution of the alcohol by volume of beers:\n",
    "sns.boxplot(beers, x = \"abv\")\n",
    "\n",
    "plt.title('Distribution of Alcohol by Volume', fontsize = 12)\n",
    "plt.xlabel('Alcohol by Volume', fontsize = 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676783499e3731da",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see that there are some beers with unrealisticly high alcohol percentages. After a research, we concluded that data coming from these beers are unreliable and we decided to eliminate the beers with more that 50 percent of alcohol by volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e99092d44a690",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.201838800Z"
    }
   },
   "outputs": [],
   "source": [
    "beers = beers[beers['abv'] < 50]\n",
    "ratings = ratings[ratings['abv'] < 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check the users and their number of ratings"
   ],
   "id": "2dfce7361d4461be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501fa1e78fbe54e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.201838800Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.histplot(users['nbr_ratings'], bins = 50, log_scale=(False, True))\n",
    "\n",
    "ax.set_title('Histogram of Number of Ratings per User', fontsize = 12)\n",
    "ax.set_xlabel('Number of Ratings', fontsize = 11)\n",
    "ax.set_ylabel('Count', fontsize = 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fd226ffd4c909",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see that there are some users with unrealistic number of rated beers. Looking at the plot, we identify users with more than 20,000 ratings as outliers and both eliminate them as users and also eliminate their ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5dd0721f73c5cd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.201838800Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_user_ids = users[users['nbr_ratings'] >= 20000]['user_id'].values\n",
    "users = users[~users['user_id'].isin(outlier_user_ids)]\n",
    "ratings = ratings[~ratings['user_id'].isin(outlier_user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Additional datasets"
   ],
   "id": "50717f84bd3f6f7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe238bd9025bac7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.201838800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading additional population datasets that will be useful for location filtering. The datasets are showing populations of all the relevant locations for 2010, which is a suitable year for our year range.\n",
    "\n",
    "us_state_populations = pd.read_csv('dataset/AdditionalData/US_state_populations.csv')\n",
    "world_population = pd.read_csv(\"dataset/AdditionalData/world_population.csv\")\n",
    "\n",
    "\n",
    "display(us_state_populations.head(5))\n",
    "display(world_population.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6169a769af15292",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Contacenating the two datasets into one and creating a location-population dictionary:\n",
    "\n",
    "us_state_populations.rename(columns = {'states': 'location'}, inplace = True)\n",
    "populations_by_location = pd.concat([us_state_populations, world_population], ignore_index = True)\n",
    "populations_by_location_dict = dict(zip(populations_by_location['location'], populations_by_location['2010']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Filtering locations to include in the study"
   ],
   "id": "3cf3394562752c28"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have meaningful results, we decided to remove the countries with a low number of users. In order to do that, we compute the proportion of users among the population. "
   ],
   "id": "c65a044eba78d969"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835b0d7d046790",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finding the portion (as percentage) of population for each location that are users in either of the websites. Then, we print the list of locations that are not present in the additional datasets. We see that all the locations are very small countries, so that exclusion of them will not be significant for our future analysis.\n",
    "\n",
    "num_users_by_location = users['location'].value_counts().reset_index()\n",
    "percentage_users_by_location = []\n",
    "missing_locations = []\n",
    "for index, row in num_users_by_location.iterrows():\n",
    "    location = row['location']\n",
    "    if location in populations_by_location_dict:\n",
    "        percentage_users_by_location.append({'location': location, 'percentage': 100 * row['count'] / populations_by_location_dict[location], 'population': populations_by_location_dict[location], 'users': row['count']})\n",
    "    else:\n",
    "        missing_locations.append(location)\n",
    "\n",
    "percentage_users_by_location = pd.DataFrame(percentage_users_by_location)\n",
    "\n",
    "print(percentage_users_by_location)  \n",
    "print(missing_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da889cec06c8dd19",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "percentage_users_by_location.sort_values(by = 'percentage', ascending = False, inplace = True)\n",
    "percentage_users_by_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cc6323f7466da",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Histogram of the populations\n",
    "\n",
    "ax = sns.histplot(percentage_users_by_location['population'], bins = 50, log_scale=(True, True))\n",
    "ax.set_title('Histogram of Number of Populations', fontsize = 12)\n",
    "ax.set_xlabel('Population', fontsize = 11)\n",
    "ax.set_ylabel('Count', fontsize = 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217926552782fed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looking at the histogram, we identify locations (countries) that have a population smaller than 100,000 as outliers and eliminate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a5d954bebb927",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "percentage_users_by_location = percentage_users_by_location[percentage_users_by_location['population'] > 1e5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eee5a893481d5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(percentage_users_by_location.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeaeff1ce73c54c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.217460400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Line plot of number of ratings by year:\n",
    "\n",
    "rating_counts_by_year = ratings['year'].value_counts().reset_index().sort_values(by = 'year')\n",
    "plt.plot(rating_counts_by_year['year'], rating_counts_by_year['count'], marker = 'o')\n",
    "\n",
    "plt.title('Histogram of Number of Populations', fontsize = 12)\n",
    "plt.xlabel('Population', fontsize = 11)\n",
    "plt.ylabel('Count', fontsize = 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd466a545fdf6d9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We need to decide on a set of years for our future analysis based on the presence of sufficient amount of data. However, looking at this line plot alone is not enough to make a decision. We want to know the number of locations with more than 50 ratings for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850f8ee8e44776e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_users = pd.merge(ratings, users[['user_id', 'nbr_ratings', 'location']], on='user_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b877799c64608f7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a dataframe that gives the rating counts of each year and location pair:\n",
    "year_location_counts = ratings_users.groupby(['year', 'location'])['user_id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e56311d529a645",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "year_location_counts_filtered = year_location_counts[year_location_counts['user_id'] >= 50]['year'].value_counts().reset_index().sort_values(by = 'year')\n",
    "plt.plot(year_location_counts_filtered['year'], year_location_counts_filtered['count'], marker = 'o')\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.axhline(y = 90, color='red', linestyle='--', label = 'Horizontal Line at y = 90')\n",
    "plt.title('Number of Locations with at least 50 Ratings, by Year', fontsize = 12)\n",
    "plt.xlabel('Year', fontsize = 11)\n",
    "plt.ylabel('# of Locations', fontsize = 11)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ef5cf1db7b0dc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see that beginning from the year 2006, the number of locations satisfying the threshold of at least 50 ratings more or less stabilizes after crossing the number of 90 locations. Due to lack of data to conclude reliable results for the earlier years, we decide to consider only the years after and including 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187c6bde3d76394",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = ratings[ratings['year'] >= 2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c7deab9f74158",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "year_location_counts = year_location_counts[year_location_counts['user_id'] >= 50]\n",
    "year_location_counts = year_location_counts[year_location_counts['year'] >= 2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4de3392b2eb12",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finding the set of locations that satisfy the at least 50 ratings limit for each year after and including 2006. These locations are identified as \"valid\".\n",
    "\n",
    "valid_year_num_by_location = year_location_counts['location'].value_counts().reset_index()\n",
    "valid_locations = valid_year_num_by_location[valid_year_num_by_location['count'] == 12]['location'].values\n",
    "valid_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468874b66c792997",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "#We decided that a sensible condition to decide the final set of locations of interest is the following: The location should be in the \"valid locations\" (at least 50 ratings for every year) AND [the percentage of users should be greater than or equal to 0.004 OR the number of users from that location should be at least 500]. This ensures that there are enough data in each year and it is representative of the whole population of the location.\n",
    "\n",
    "final_locations = percentage_users_by_location[percentage_users_by_location['location'].isin(valid_locations) & ((percentage_users_by_location['percentage'] >= 0.004) | (percentage_users_by_location['users'] >= 500))]['location']\n",
    "\n",
    "all_locations = final_locations.tolist()\n",
    "\n",
    "final_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We fixed some of the brewery locations manually such as mapping individual locations in Canada into one common name \"Canada\" and manually searching for the brewery locations on the web that were given as website URL's. We gathered the necessary updates in a dictionary and updated the brewery locations accordingly.\n",
    "\n",
    "brewery_name_correction_dict = {'Canada, Alberta': 'Canada', 'Canada, British Columbia': 'Canada', 'Canada, Manitoba': 'Canada', 'Canada, New Brunswick': 'Canada', 'Canada, Newfoundland and Labrador': 'Canada', 'Canada, Nova Scotia': 'Canada', 'Canada, Ontario': 'Canada', 'Canada, Quebec': 'Canada', 'Canada, Saskatchewan': 'Canada', 'Illinois</a>, 60614-4939, <a href=\"/place/directory/9/US/\">United States': 'United States, Illinois', 'New York</a>, 13057, <a href=\"/place/directory/9/US/\">United States': 'United States, New York', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://barleysbrewing.com\" target=\"_blank\">barleysbrewing.com': 'United States, Ohio', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://bigbuck.com\" target=\"_blank\">bigbuck.com': 'United States, Michigan', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://bjsrestaurants.com\" target=\"_blank\">bjsrestaurants.com': 'United States, California', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://bluecorncafe.com\" target=\"_blank\">bluecorncafe.com': 'United States, North Carolina', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://buckheadbrewery.com\" target=\"_blank\">buckheadbrewery.com': 'United States, Georgia', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://capcitybrew.com\" target=\"_blank\">capcitybrew.com': 'United States, Washington', 'United States, Washington DC': 'United States, Washington', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://empirebrewco.com\" target=\"_blank\">empirebrewco.com': 'United States, New York', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://eotrading.com\" target=\"_blank\">eotrading.com': 'United States, California', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://fullsailbrewing.com\" target=\"_blank\">fullsailbrewing.com': 'United States, Oregon', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://gcfb.net\" target=\"_blank\">gcfb.net': 'United States, Minnesota', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://gordonbiersch.com\" target=\"_blank\">gordonbiersch.com': 'United States, California', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://herefordandhops.com\" target=\"_blank\">herefordandhops.com': 'United States, Michigan', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://hopsonline.com\" target=\"_blank\">hopsonline.com': 'United States, New Mexico', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://ilvicino.com\" target=\"_blank\">ilvicino.com': 'United States, New Mexico', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://ironhillbrewery.com\" target=\"_blank\">ironhillbrewery.com': 'United States, Pennsylvania', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://leinie.com\" target=\"_blank\">leinie.com': 'United States, Wisconsin', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://mcmenamins.com\" target=\"_blank\">mcmenamins.com': 'United States, Oregon', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://mendobrew.com\" target=\"_blank\">mendobrew.com': 'United States, California', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://rockbottom.com\" target=\"_blank\">rockbottom.com': 'United States, Colorado', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://seadogbrewing.com\" target=\"_blank\">seadogbrewing.com': 'United States, Maine', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://sebagobrewing.com\" target=\"_blank\">sebagobrewing.com': 'United States, Maine', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://shipyard.com\" target=\"_blank\">shipyard.com': 'United States, Maine', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://snakeriverbrewing.com\" target=\"_blank\">snakeriverbrewing.com': 'United States, Wyoming', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://sonorabrew.com\" target=\"_blank\">sonorabrew.com': 'United States, California', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://steelheadbrewingco.com\" target=\"_blank\">steelheadbrewingco.com': 'United States, Oregon', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://theram.com\" target=\"_blank\">theram.com': 'United States, Oregon', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://thirstydog.com\" target=\"_blank\">thirstydog.com': 'United States, Ohio', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://tiedhouse.com\" target=\"_blank\">tiedhouse.com': 'United States, Pennsylvania', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://triumphbrew.com\" target=\"_blank\">triumphbrew.com': 'United States, New Jersey', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://tworows.com\" target=\"_blank\">tworows.com': 'United States, Texas', 'United States</a> | <a href=\"http://maps.google.com/maps?oi=map&q=%2C+US\" target=\"_blank\">map</a><br><a href=\"http://weepingradish.com\" target=\"_blank\">weepingradish.com': 'United States, North Carolina', 'Utah</a><br><a href=\"http://utahbeers.com\" target=\"_blank\">utahbeers.com': 'United States, Utah'}\n",
    "\n",
    "breweries['location'] = breweries['location'].replace(brewery_name_correction_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a1f1620c574dd8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d850f72ea6bf2c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving the filtered data:\n",
    "\n",
    "users = users[users['location'].isin(all_locations)]\n",
    "ratings = ratings[ratings['user_id'].isin(users['user_id'].unique())]\n",
    "\n",
    "beers.to_csv(\"dataset/FilteredData/beers.csv\", index = False)\n",
    "breweries.to_csv(\"dataset/FilteredData/breweries.csv\", index = False)\n",
    "users.to_csv(\"dataset/FilteredData/users.csv\", index = False)\n",
    "ratings.to_csv(\"dataset/FilteredData/ratings.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dd128ee17ffe3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### PART 3: Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df67938a0c30cda",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.  Visualizations on the World Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94b0e8f1b42967",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.233082100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using a function that returns the corresponding latitude and longitude of the input location name, we put all our final location set on the world map to visualize their geographical distribution.\n",
    "\n",
    "def geocode_location(location_name):\n",
    "    geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "    location = geolocator.geocode(location_name)\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "location_latitudes_longitudes = []\n",
    "location_latitudes_longitudes_tuples = []\n",
    "for location in all_locations:\n",
    "    res = geocode_location(location)\n",
    "    if res:\n",
    "        lat,long = res\n",
    "        location_latitudes_longitudes.append([lat, long])\n",
    "        location_latitudes_longitudes_tuples.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd55a59214b204",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "map_center = [20,0]\n",
    "my_map = folium.Map(location = map_center, zoom_start = 1)\n",
    "\n",
    "for i, location in enumerate(all_locations):\n",
    "    folium.CircleMarker(location = location_latitudes_longitudes[i], radius = 5, color='blue', fill=True, fill_color='blue', fill_opacity = 0.7, popup = location).add_to(my_map)\n",
    "    \n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e91e97dbc595b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One can see that our set of locations are distributed such that they are mainly populated around North America and North Europe. However, we have also some outliers that are far away from these groups, such as New Zealand or Australia. Such a contrast could allow us to investigate and compare/contrast the trend behaviour among the neighbor locations as well as more separated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d07f3993220078",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using a function that returns the corresponding latitude and longitude of the input location name, we put all our brewery locations on the world map to visualize their geographical distribution.\n",
    "\n",
    "all_brewery_locations = breweries['location'].tolist()\n",
    "all_distinct_brewery_locations = list(set(all_brewery_locations))\n",
    "brewery_latitudes_longitudes = []\n",
    "my_map = folium.Map(location = [20, 0], zoom_start = 3)\n",
    "for location in all_distinct_brewery_locations:\n",
    "    try:\n",
    "        res = geocode_location(location)\n",
    "    except:\n",
    "        continue\n",
    "    if res:\n",
    "        lat,long = res\n",
    "        brewery_latitudes_longitudes.append([lat, long])\n",
    " \n",
    "#Using a heatmap to better indicate the density of breweries per location:        \n",
    "HeatMap(brewery_latitudes_longitudes).add_to(my_map)\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc90188cab32df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Popularity and Rating Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b732d7b8adc5d27",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.2.1: Initial Analysis of Style Trends by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84debc5c1f05ba6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the most popular (in quantity) beer style for each location by looking at the total number of ratings by year. We also put a threshold of 5 that needs to be satisfied for a location-style pair to be considered in this analysis.\n",
    "\n",
    "years = np.arange(2006, 2018)\n",
    "style_popularities_by_year = pd.DataFrame()\n",
    "for year in years:\n",
    "    location_style = location_style_stats(ratings.copy(), users.copy(), year, 5)\n",
    "    location_style_groupedby_loc = location_style.groupby('location')\n",
    "    idx_most_popular = location_style_groupedby_loc['number'].idxmax()\n",
    "    most_popular_styles_by_location = location_style.loc[idx_most_popular]\n",
    "    most_popular_styles_by_location = most_popular_styles_by_location[['location', 'style']]\n",
    "    most_popular_styles_by_location.set_index('location', inplace = True)\n",
    "    most_popular_styles_by_location = most_popular_styles_by_location.rename(columns = {'style': str(year)})\n",
    "    style_popularities_by_year = pd.concat([style_popularities_by_year, most_popular_styles_by_location], axis = 1)\n",
    "\n",
    "style_popularities_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e184f0d3d0376",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the highest rated beer style for each location by looking at the average rating by year. We also put a threshold of 5 that needs to be satisfied for a location-style pair to be considered in this analysis.\n",
    "\n",
    "years = np.arange(2006,2018)\n",
    "\n",
    "style_ratings_by_year = pd.DataFrame()\n",
    "for year in years:\n",
    "    location_style = location_style_stats(ratings.copy(), users.copy(), year, 5)\n",
    "    location_style_groupedby_loc = location_style.groupby('location')\n",
    "    idx_highest_rated = location_style_groupedby_loc['z_score'].idxmax()\n",
    "    highest_rated_styles_by_location = location_style.loc[idx_highest_rated]\n",
    "    highest_rated_styles_by_location = highest_rated_styles_by_location[['location', 'style']]\n",
    "    highest_rated_styles_by_location.set_index('location', inplace = True)\n",
    "    highest_rated_styles_by_location = highest_rated_styles_by_location.rename(columns = {'style': str(year)})\n",
    "    style_ratings_by_year = pd.concat([style_ratings_by_year, highest_rated_styles_by_location], axis = 1)\n",
    "\n",
    "style_ratings_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef64a02fccb19f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.2.2: Initial Analysis of Brewery Trends by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2643b8cdce675",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the most popular (in quantity) beer production place (brewery location) for each location by looking at the total number of ratings. We also put a threshold of 5 that needs to be satisfied for a location-brewery location pair to be considered in this analysis.\n",
    "\n",
    "years = np.arange(2006,2018)\n",
    "bc_popularities_by_year = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    location_bc = location_brewery_country_stats(ratings.copy(), users.copy(), breweries.copy(), year, 5)\n",
    "    location_bc_gb_loc = location_bc.groupby('location')\n",
    "    idx_most_popular = location_bc_gb_loc['number'].idxmax()\n",
    "    most_popular_bc_by_location = location_bc.loc[idx_most_popular]\n",
    "    most_popular_bc_by_location = most_popular_bc_by_location[['location', 'brewery_location']]\n",
    "    most_popular_bc_by_location.set_index('location', inplace = True)\n",
    "    most_popular_bc_by_location = most_popular_bc_by_location.rename(columns = {'brewery_location': str(year)})\n",
    "    bc_popularities_by_year = pd.concat([bc_popularities_by_year, most_popular_bc_by_location], axis = 1)\n",
    "    \n",
    "bc_popularities_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e355244a40505f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the highest rated beer production location for each location by looking at the average rating by year. We also put a threshold of 10 that needs to be satisfied for a location-brewery location pair to be considered in this analysis.\n",
    "\n",
    "years = np.arange(2006, 2018)\n",
    "bc_ratings_by_year = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    location_bc = location_brewery_country_stats(ratings.copy(), users.copy(), breweries.copy(), year, 10)\n",
    "    location_bc_gb_loc = location_bc.groupby('location')\n",
    "    idx_highest_rated = location_bc_gb_loc['z_score'].idxmax()\n",
    "    highest_rated_bc_by_location = location_bc.loc[idx_highest_rated]\n",
    "    highest_rated_bc_by_location = highest_rated_bc_by_location[['location', 'brewery_location']]\n",
    "    highest_rated_bc_by_location.set_index('location', inplace=True)\n",
    "    highest_rated_bc_by_location = highest_rated_bc_by_location.rename(columns={'brewery_location': str(year)})\n",
    "    bc_ratings_by_year = pd.concat([bc_ratings_by_year, highest_rated_bc_by_location], axis=1)\n",
    "    \n",
    "bc_ratings_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316f36b4b2d7399",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3. Example: Distance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0aa5f93f071a9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "ll_dict = dict(zip(all_locations, location_latitudes_longitudes_tuples))\n",
    "ll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f404c972ab4703",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.248509100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Printing examples of distances between three location pairs using geodesic() function:\n",
    "\n",
    "print(f\"Distance between New York and Ohio is {geodesic(ll_dict['United States, New York'], ll_dict['United States, Ohio']).kilometers:.2f} kilometers.\")\n",
    "\n",
    "print(f\"Distance between Brazil and Germany is {geodesic(ll_dict['Brazil'], ll_dict['Germany']).kilometers:.2f} kilometers.\")\n",
    "\n",
    "print(f\"Distance between Iceland and New Zealand is {geodesic(ll_dict['Iceland'], ll_dict['New Zealand']).kilometers:.2f} kilometers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e500e144ea087",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4. Initial Regression and Correlation Analysis\n",
    "\n",
    "We study the correlation between the different aspects of the beers, and their rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142f62073eeaa95",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.264142300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Linear regression of the rating suing the features \"appearance\", \"aroma\", \"palate\" and \"taste\".\n",
    "\n",
    "mod = smf.ols(formula = 'rating ~ appearance + aroma + palate + taste', data = ratings)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ea07dd34edabf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The results suggest that the taste property is the most important and the appearance property is the least important factor for a beer to receive a higher rating. Furthermore, p-values for all the coefficients are 0.000 and explained variance (R-squared) is 0.962. This shows that the rating is highly correlated and explainable with the given features, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3497e6a74e8801",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-12T09:48:38.264142300Z"
    }
   },
   "outputs": [],
   "source": [
    "corr, p_value = stats.pearsonr(ratings['abv'], ratings['rating'])\n",
    "\n",
    "print(f\"Pearson correlation between alcohol by volume and rating is {corr:.3f} with a p value of {p_value:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c26502b7e6880",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see that alcohol by volume is significantly correlated with higher ratings, with a pearson correlation coefficient of 0.350. Furthermore, p_value is given as 0.000, meaning that having no actual correlation between them but still observing the data we have is almost impossible. This is a rather surprising and remarkable finding to have in mind for our future analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
